---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.7
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region id="KzcJPH0e1BE6" -->
# imports
<!-- #endregion -->

```{python colab={'base_uri': 'https://localhost:8080/'}, id="kEr9J20VzxOq", outputId="b88a69f2-0a15-4bfc-a660-a7a3bf9ad751"}
import pandas as pd
import numpy as np
import datetime
import matplotlib.pyplot as plt
import pmdarima as pm
import warnings
from pmdarima.arima import ARIMA
from math import sqrt
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
```

```{python}
warnings.filterwarnings("ignore")
```

<!-- #region id="uEOhGFuj2J3p" -->
# loading Dataset
<!-- #endregion -->

```{python}
INPUT_PATH = 'data/labels.parquet'
OUTPUT_PATH = 'data/arima_predict.parquet'
```

```{python id="xLg8mI4Yr8Zc"}
def load_data(path):
    dataset = pd.read_parquet(path, engine = 'pyarrow') 
    return dataset
```

```{python}
rides_df = load_data(INPUT_PATH)
```

# Preprocessing 

```{python}
def preprocessing(rides_df):
    loc_ts={}
    demand=[]
    pre_Location=1
    
    for i in range(len(rides_df)):
        
      if rides_df.Location[i]!=pre_Location:
        loc_ts[f'LocationID_{pre_Location}']=demand
        demand=[]
          
      demand.append(rides_df.Demand[i])
      pre_Location = rides_df.Location[i]
        
    loc_ts[f'LocationID_{pre_Location}'] = demand
    loc_labels_df = pd.DataFrame(loc_ts)
    
    return loc_labels_df
```

```{python}
loc_labels_df = preprocessing(rides_df)
print(f'loc_labels_df shape : {loc_labels_df.shape}')
loc_labels_df.head()
```

<!-- #region id="7fgxL33c7yRz" -->
# ARIMA MODEL
<!-- #endregion -->

<!-- #region id="Ty2gmgJ3Yuig" -->
## train 
<!-- #endregion -->

```{python id="HafiobWpYqiK"}
col = loc_labels_df.columns
train_size_ratio = 0.2
```

```{python id="QWWSsvJwVWaR"}
def split_data(loc_labels_df, location, train_size_ratio):
    size = int(len(loc_labels_df) * train_size_ratio)
    val_tr = loc_labels_df.loc[0:size, location]
    val_te = loc_labels_df.loc[size:, location]
    return (val_tr, val_te)
```

```{python id="jbk1N0pkxIPy"}
def arima_forecast(val_tr, val_te):
    history = [x for x in val_tr]
    predictions = []
    model = pm.arima.auto_arima(
                              history, start_p=1, start_q=1,
                              test='kpss', max_p=8, max_q=8,
                              seasonal=False, m=1,
                              d=None, start_P=0,
                              suppress_warnings=False, trace=False)
    for t in range(len(val_te)):
        best_arima_model_fit = pm.arima.ARIMA(order=model.get_params().get("order")).fit(history)
        output = best_arima_model_fit.predict(n_periods=1)
        yhat = output[0]
        predictions.append(int(yhat))
        obs = val_te.iloc[t]
        history.append(obs)
    
    val_te = val_te.reset_index()
    return (val_te.iloc[:,1], predictions,
          history, best_arima_model_fit.fittedvalues())

```

<!-- #region id="SllaVhLm3UCg" -->
train and predict for all locationIDs

<!-- #endregion -->

```{python id="SqRKbhM_rgY8"}
def rmse(val_te, predictions):
  rmse = sqrt(mean_squared_error(val_te, predictions))
  return rmse
```

```{python id="gD4cUUg1rlUd"}
def mape(val_te, predictions):
  mape = mean_absolute_percentage_error(val_te, predictions)
  return mape
```

```{python colab={'base_uri': 'https://localhost:8080/'}, id="qMqwNRrNH6YE", outputId="382f9add-f885-4cef-a464-8f7aef0c34d8"}
def predict_all_location(loc_labels_df, col, train_size_ratio):
    all_loc_rmse = []
    all_loc_mape = []
    val_predicted = {}
    val_test = {}
    val_fit = {}
    for loc in col:
        val_tr, val_te = split_data (loc_labels_df, loc, train_size_ratio)
        result = arima_forecast(val_tr, val_te)
        val_rmse = rmse (result[0], result[1])
        val_mape = mape (result[0], result[1])
        all_loc_rmse.append(val_rmse)
        all_loc_mape.append(val_mape)
        val_test[loc] = result[0]
        val_predicted[loc] = result[1]
        val_fit[loc] = result[3]
    
    val_test = pd.DataFrame(val_test)
    val_fit = pd.DataFrame(val_fit)
    val_predicted = pd.DataFrame(val_predicted)
    return (val_test, val_predicted, val_fit, all_loc_rmse, all_loc_mape)
```

```{python}
val_test, val_predicted, val_fit, all_loc_rmse, all_loc_mape = predict_all_location(loc_labels_df, col, train_size_ratio)
```

<!-- #region id="t9TmKfCS3Fpx" -->
## evaluation
<!-- #endregion -->

```{python}
def minmax_error(val_predicted, val_test):
    error = val_predicted-val_test
    min_max_error = pd.concat([error.abs().min(axis=0),error.abs().max(axis=0)], axis=1,sort=False)
    min_max_error.columns = ['min', 'max']
    
    return min_max_error
```

```{python}
min_max_error = minmax_error(val_predicted, val_test)
min_max_error.head()
```

# Save file

```{python}
def save_val_predicted(dataset, path):
    labels_df = dataset.to_parquet(path, index=False)
```

```{python}
save_val_predicted(val_predicted, OUTPUT_PATH)
```

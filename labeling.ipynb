{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, urls, file_name, force_update=False):\n",
    "    if os.path.exists(path) and (not force_update):\n",
    "        pass\n",
    "    else:\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        for index in range(len(urls)):\n",
    "            response = requests.get(urls[index])\n",
    "            name = path + file_name + str(index + 1) + '.parquet'\n",
    "\n",
    "            with open(name, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "    dataset = []\n",
    "    for i in range(len(urls)):\n",
    "        name = path + file_name + str(i + 1) + '.parquet'\n",
    "        data = pd.read_parquet(name)\n",
    "        dataset.append(data)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet',\n",
    "        'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-04.parquet']\n",
    "\n",
    "data = load_data('datasets/', urls, file_name='yellow_tripdata_2023-0')\n",
    "\n",
    "data_1_raw = pd.DataFrame(data[0])\n",
    "data_2_raw = pd.DataFrame(data[1])\n",
    "data_3_raw = pd.DataFrame(data[2])\n",
    "data_4_raw = pd.DataFrame(data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data_based_on_date(dataset, start_date: str, end_date: str):\n",
    "    # create date from str\n",
    "    start_date = datetime.date.fromisoformat(start_date)\n",
    "    end_date = datetime.date.fromisoformat(end_date)\n",
    "    clean_dataset = dataset[(dataset['tpep_pickup_datetime'].dt.date >= start_date) &\n",
    "                            (dataset['tpep_pickup_datetime'].dt.date <= end_date)]\n",
    "\n",
    "    return clean_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = clean_data_based_on_date(data_1_raw, '2023-01-01', '2023-01-31')   # January\n",
    "data_2 = clean_data_based_on_date(data_2_raw, '2023-02-01', '2023-02-28')   # February\n",
    "data_3 = clean_data_based_on_date(data_3_raw, '2023-03-01', '2023-03-31')   # March\n",
    "data_4 = clean_data_based_on_date(data_4_raw, '2023-04-01', '2023-04-30')   # April"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1 shape : (3066718, 19)\n",
      "data_2 shape : (2913900, 19)\n",
      "data_3 shape : (3403577, 19)\n",
      "data_4 shape : (3288155, 19)\n"
     ]
    }
   ],
   "source": [
    "print(f\"data_1 shape : {data_1.shape}\")\n",
    "print(f\"data_2 shape : {data_2.shape}\")\n",
    "print(f\"data_3 shape : {data_3.shape}\")\n",
    "print(f\"data_4 shape : {data_4.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_date_from_datetime(dataset, date_col_name: str, datetime_col_name: str):\n",
    "    dataset[date_col_name] = pd.to_datetime(dataset[datetime_col_name].dt.date)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_demand_for_each_loc_and_date(dataset):\n",
    "    return dataset.groupby(['PULocationID', 'PU_date'])['PU_date'].count().to_frame('Demand')\\\n",
    "        .sort_values(['PULocationID', 'PU_date'], ascending=[True, True]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_dataset_for_each_location(dataset, location_id, start_date, end_date):\n",
    "    # create data frame for each location\n",
    "    sub_df = pd.DataFrame({'location': location_id, 'date': pd.date_range(start=start_date, end=end_date)})\n",
    "    sub_df['Demand'] = 0\n",
    "    for i in range(len(sub_df)):\n",
    "        loc_date_row = dataset[(dataset['PULocationID']==sub_df['location'][i]) & (dataset['PU_date']==sub_df['date'][i])]\n",
    "        if not loc_date_row.empty:\n",
    "            sub_df['Demand'][i] = loc_date_row['Demand']\n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(dataset):\n",
    "    start_date = dataset['PU_date'].min()\n",
    "    end_date = dataset['PU_date'].max()\n",
    "\n",
    "    location_ids = dataset.PULocationID.unique()\n",
    "    sub_dfs = []\n",
    "    for location_id in location_ids:\n",
    "        sub_dfs.append(complete_dataset_for_each_location(dataset, location_id, start_date, end_date))\n",
    "    data_modified = pd.concat(sub_dfs).reset_index(drop=True)\n",
    "    return data_modified\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = add_date_from_datetime(data_1, 'PU_date', 'tpep_pickup_datetime')\n",
    "data_2 = add_date_from_datetime(data_2, 'PU_date', 'tpep_pickup_datetime')\n",
    "data_3 = add_date_from_datetime(data_3, 'PU_date', 'tpep_pickup_datetime')\n",
    "data_4 = add_date_from_datetime(data_4, 'PU_date', 'tpep_pickup_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1_sort_by_PUloc_PUdate = count_demand_for_each_loc_and_date(data_1)\n",
    "data_2_sort_by_PUloc_PUdate = count_demand_for_each_loc_and_date(data_2)\n",
    "data_3_sort_by_PUloc_PUdate = count_demand_for_each_loc_and_date(data_3)\n",
    "data_4_sort_by_PUloc_PUdate = count_demand_for_each_loc_and_date(data_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenating all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_data_by_loc_date = pd.concat([data_1_sort_by_PUloc_PUdate, data_2_sort_by_PUloc_PUdate,\n",
    "                                     data_3_sort_by_PUloc_PUdate, data_4_sort_by_PUloc_PUdate]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_label(concat_data_by_loc_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_labels(labels_df, path):\n",
    "    with open(path, 'w', encoding='utf-8-sig') as f:\n",
    "        labels_df.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_labels(labels, 'labeling/labels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

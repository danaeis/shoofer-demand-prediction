---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.7
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region id="8UTIGpTZZlOO" -->
# Imports
<!-- #endregion -->

```{python id="AnwSHO1L97I5"}
import datetime
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import shap
import xgboost as xgb
import warnings
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
from sklearn.model_selection import GridSearchCV
```

```{python}
warnings.filterwarnings('ignore')
```

<!-- #region id="pSSMa3G2wGmF" -->
# Configs
<!-- #endregion -->

```{python id="zIkDLK9zwGmG"}
INPUT_PATH = '/Users/maedeh/Desktop/demand_project/demand_project/shoofer-demand-prediction/data/features_df_phase2.parquet'
Ridge_PATH = '/Users/maedeh/Desktop/demand_project/demand_project/shoofer-demand-prediction/data/Ridge_predictions_phase2.parquet'
XGB_ridge_PATH = '/Users/maedeh/Desktop/demand_project/demand_project/shoofer-demand-prediction/data/XGB_ridge_predictions_phase2.parquet'
XGB_PATH = '/Users/maedeh/Desktop/demand_project/demand_project/shoofer-demand-prediction/data/XGB_predictions_phase2.parquet'
OUTPUT_PATH = XGB_PATH

# FEATURE_menu = [
#                 'previous_day_interval', 
#                 'previous_2day_interval',
#                 'previous_3day_interval',
#                 'previous_4day_interval',
#                 'previous_5day_interval',
#                 'previous_6day_interval',
#                 'previous_week_interval',
#                 'previous_8day_interval',
#                 'previous_9day_interval',
#                 'previous_10day_interval',
#                 'previous_11day_interval',
#                 'previous_12day_interval',
#                 'previous_13day_interval',
#                 'previous_2week_interval'
#                ]

FEATURE_LIST = [
                'previous_day_interval', 
                'previous_week_interval',
                'previous_2week_interval'
               ]


TEST_START_DATE = '2023-04-1'

AUTO_TUNE = True
add_ridge_feature = True
```

<!-- #region id="5eS5BQE9wGmK" -->
# Data preparation

<!-- #endregion -->

<!-- #region id="TWsjXbpaznc_" -->
## Load Data
<!-- #endregion -->

```{python}
def load_data(INPUT_PATH):
    features_df = pd.read_parquet(INPUT_PATH, engine='pyarrow')
    return features_df
```

```{python id="87BFHUu1-z73"}
features_df = load_data(INPUT_PATH)
```

```{python id="hCN-11QT3bp1"}
print(f'features dataframe shape : {features_df.shape}')
features_df.head()
```

```{python}
ridge_df = pd.read_parquet(Ridge_PATH)
```

```{python}
print(f'rides dataframe shape : {ridge_df.shape}')
ridge_df.head()
```

## Add feature

```{python}
def add_feature(dataset, lag_num):
    
    for i in range(1,lag_num+1):
        if i not in(1,7):
            dataset[f'previous_{i}day_interval'] = dataset.groupby('Location')['Demand'].shift(i*8)

    return dataset
```

```{python}
new_features_df = add_feature(features_df, lag_num = 13)
print(f'new features dataframe shape : {new_features_df.shape}')
new_features_df.head()
```

```{python}
def feature_selection(dataset, FEATURE_LIST):
    
    dataset = dataset[['Location','Date','Hour_interval','Demand']+FEATURE_LIST]
    dataset.dropna(inplace = True)
    
    return dataset
```

```{python}
selected_features_df = feature_selection(new_features_df, FEATURE_LIST)
print(f'features dataframe shape : {selected_features_df.shape}')
selected_features_df.head()
```

```{python}
def join_ridge_feature(dataset, ridge_df, FEATURE_LIST):

    dataset = dataset.merge(ridge_df, how='outer', on = ['Location','Date','Hour_interval'])
    FEATURE_LIST.append('Predicted_demand')
    
    return dataset, FEATURE_LIST
```

```{python}
if add_ridge_feature:
    selected_features_df, FEATURE_LIST = join_ridge_feature(selected_features_df, ridge_df, FEATURE_LIST)
    print(f'final features dataframe shape : {selected_features_df.shape}')
selected_features_df.head()
```

```{python}
print(f'Feature list: {FEATURE_LIST}') 
```

<!-- #region id="zN0kp6jw03DP" -->
## Split Train and Test Data
<!-- #endregion -->

```{python id="CMY1G1lmwGmI"}
def train_test_splitting(dataset, TEST_START_DATE):
    
    train_df = dataset[dataset['Date'] < TEST_START_DATE]
    test_df = dataset[dataset['Date'] >= TEST_START_DATE]

    return train_df, test_df
```

```{python id="3xH4VMGNwGmK"}
train_df, test_df = train_test_splitting(selected_features_df, TEST_START_DATE)
```

```{python id="xxGdRZfqwGmL"}
print(f'train dataframe shape : {train_df.shape}')
train_df.head()
```

```{python id="uPbINwH224Hy"}
print(f'test dataframe shape : {test_df.shape}')
test_df.head()
```

<!-- #region id="xf8ChW_7wGmL" -->
# Model Training
<!-- #endregion -->

<!-- #region id="mIhvw9lH92sa" -->
## **Gradient Boosting Regressor**
<!-- #endregion -->

<!-- #region id="13gFIyYfZyxh" -->
### Model Tuning
<!-- #endregion -->

```{python id="sOMPo5ryBm8g"}
def grid_search(model, test_parameters, train_data, feature_list, cv = None):
    gs = GridSearchCV(
        estimator = model, 
        param_grid = test_parameters, 
        scoring = 'neg_root_mean_squared_error', 
        cv = cv, 
        n_jobs = -1
        )
    
    gs.fit(train_data[feature_list], train_data['Demand'])
    return gs.best_params_, gs.best_score_
```

```{python id="cm3YTQCMZVvu", outputId="4cf0ed3b-0243-476a-af87-35db760c9e5c"}
if AUTO_TUNE:
    params_test = {'learning_rate':[0.06, 0.03, 0.01], 
                'subsample':[0.9], 
                'colsample_bytree':[0.6, 0.8], 
                'max_depth':[7], 
                'gamma':[5, 10],
                'n_estimators':[1000]
                }
    params = {"objective": "reg:squarederror"}

    best_params, best_score = grid_search(
        model = xgb.XGBRegressor(**params), 
        test_parameters = params_test,
        train_data = train_df, 
        feature_list = FEATURE_LIST, 
        cv = 3
        )
    
    print(best_params, best_score)
else:
    best_params = {'colsample_bytree': 0.8, 
                   'gamma': 10, 
                   'learning_rate': 0.01, 
                   'max_depth': 7, 
                   'subsample': 0.9, 
                   'n_estimators': 1000
                   }
```

<!-- #region id="H0IHB8t41NB6" -->
### Prediction
<!-- #endregion -->

```{python id="pbhM5Oe6PjW7"}
def model_predict(model, train_data, test_data, feature_list):

    model.fit(train_data[feature_list], train_data['Demand'])
    
    train_predict_df  = model.predict(train_data[feature_list])
    test_predict_df  = model.predict(test_data[feature_list])

    return train_predict_df, test_predict_df
```

```{python id="5AdQtdSqN7m9"}
model = xgb.XGBRegressor(**best_params)
train_prediction_df, test_prediction_df = model_predict(model, train_df, test_df, FEATURE_LIST)
```

<!-- #region id="J0EYl9KtTfo7" -->
### Visualization
<!-- #endregion -->

```{python id="ao6nw8xsRvB9"}
def prediction_visualization(train_data, test_data, train_prediction_df, test_prediction_df):

    predicted_train_df = train_data
    predicted_test_df = test_data
    predicted_train_df['Predicted'] = train_prediction_df
    predicted_test_df['Predicted'] = test_prediction_df
    
    train_data = train_data.groupby(['Date','Hour_interval'])['Demand'].sum()
    test_data = test_data.groupby(['Date','Hour_interval'])['Demand'].sum()
    predicted_train_df = predicted_train_df.groupby(['Date','Hour_interval'])['Predicted'].sum()
    predicted_test_df = predicted_test_df.groupby(['Date','Hour_interval'])['Predicted'].sum()

    plt.figure(figsize=(30,10))
    plt.title('Train', fontsize = 30)
    plt.plot(range(1,len(train_data)+1), train_data)
    plt.plot(range(1,len(train_data)+1), predicted_train_df)
    plt.xlabel('time interval', fontsize = 15)
    plt.legend(["Real Value", "Predicted"], loc ="lower right", fontsize = 15)
    plt.show()

    plt.figure(figsize=(30,10))
    plt.title('Test', fontsize = 30)
    plt.plot(range(1,len(test_data)+1), test_data)
    plt.plot(range(1,len(test_data)+1), predicted_test_df)
    plt.xlabel('time interval', fontsize = 15)
    plt.legend(["Real Value", "Predicted"], loc ="lower right", fontsize = 15)
    plt.show()
```

```{python id="deyLWLmZThMJ", outputId="4d0094aa-099c-490f-aa82-281ee16bae01"}
prediction_visualization(train_df, test_df, train_prediction_df, test_prediction_df)
```

<!-- #region id="lERphf0kTist" -->
### Evaluation
<!-- #endregion -->

```{python id="BcGvcilUWEEC"}
def evaluate(metric, metric_name, true_values, predicted_values):
    print(f'{metric_name} : {metric(true_values, predicted_values)}')
```

```{python}
def smape(y_true, y_pred):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred))
    smape = np.mean(numerator / denominator)
    return smape * 100
```

```{python id="v4-GWghuSbnA"}
def evaluation(model_name, train_df, test_df, train_prediction_df, test_prediction_df):
    print(f'{model_name} train scores:')


    evaluate(mean_absolute_error, 'MAE', train_df['Demand'], train_prediction_df)
    evaluate(mean_squared_error, 'MSE', train_df['Demand'], train_prediction_df)
    evaluate(mean_absolute_percentage_error, 'MAPE', train_df['Demand'], train_prediction_df)
    evaluate(smape, 'smape', train_df['Demand'], train_prediction_df)

    print(f'{model_name} test scores:')

    evaluate(mean_absolute_error, 'MAE', test_df['Demand'], test_prediction_df)
    evaluate(mean_squared_error, 'MSE', test_df['Demand'], test_prediction_df)
    evaluate(mean_absolute_percentage_error, 'MAPE', test_df['Demand'], test_prediction_df)
    evaluate(smape, 'smape', test_df['Demand'], test_prediction_df)

```

```{python id="qSZwIFprTkqK", outputId="7ae94952-ec22-410a-9d26-6e05a96af6ab"}
evaluation('XGB', train_df, test_df, train_prediction_df, test_prediction_df)
```

<!-- #region id="_286hlGi7VWD" -->
### Feature Importance and SHAPE
<!-- #endregion -->

```{python id="osueYsNP1NB8", outputId="b3c13ee6-bd74-4470-a8c5-558df5416e28"}
xgb.plot_importance(model)
plt.show()
```

```{python id="50CEqbp75Y_i", outputId="b7288f1d-517a-4707-da22-ad996453f161"}
dtrain_reg = xgb.DMatrix(train_df[FEATURE_LIST].values, train_df['Demand'].values, enable_categorical=True)

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(dtrain_reg)
shap.summary_plot(shap_values, train_df[FEATURE_LIST])
```

# File Saving

```{python}
def save_predictions(dataset, path):
    dataset.to_parquet(path, index=False)
```

```{python}
def prediction_labeling(pred_df, labeled_df):
    labeled_df.reset_index(inplace = True)
    labeled_prediction_df = labeled_df[['Location', 'Date', 'Hour_interval']]
    labeled_prediction_df['Predicted_demand'] = pred_df
    return labeled_prediction_df
```

```{python}
labeled_prediction_df = prediction_labeling(test_prediction_df, test_df)
```

```{python}
print(f'labeled prediction dataframe shape : {labeled_prediction_df.shape}')
labeled_prediction_df.head()
```

```{python}
if add_ridge_feature:
    OUTPUT_PATH = XGB_ridge_PATH

save_predictions(labeled_prediction_df, OUTPUT_PATH)
```

```{python}

```

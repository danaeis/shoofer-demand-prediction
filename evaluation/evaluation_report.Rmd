---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.14.7
  kernelspec:
    display_name: demandenv
    language: python
    name: python3
---

# Imports

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import warnings
from tabulate import tabulate
```

# Configs

```{python}
LABELED_PATH = "../data/results/labels.parquet"
PREDICTED_XGB_PATH = "../data/results/xgb_prediction_labeled.parquet"
PREDICTED_XGB_ARIMA_PATH = "../data/results/xgb_predictions_tuned.parquet"
PREDICTED_REGRESSION_PATH = "../data/results/ridge_predictions.parquet"
PREDICTED_ARIMA_PATH = "../data/results/arima_predict.parquet"
TEST_START_DATE = '2023-04-01'
IMPORTANT_LOCATIONS = 50
SAVE_PLOT_PATH = '../data/pngs/'
warnings.filterwarnings('ignore')
```

```{python}
report_dict = {
    'MAPE':{
        'important_lacations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'others_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'all_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        }
        
    },    
    'MAE':{
        'important_lacations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'others_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'all_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        }
        
    },
    'MSE':{
        'important_lacations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'others_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'all_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        }
        
    },
    'RMSE':{
        'important_lacations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'others_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        },
        'all_locations':{
            'baseline_last_week':None,
            'model_regression':None,
            'model_xgboost':None
        }
        
    },
    
}
```

```{python}
predictions_dict = {
    'baseline_last_day':None,
    'baseline_last_week':None,
    'model_regression':None,
    'model_xgboost':None,
}
```

```{python}
sorted_locations_dict={
    'baseline_last_week':None,
    'model_regression':None,
    'model_xgboost':None,
}
```

```{python}
predictions_mean_error_dict={
    
    'baseline_last_week':
    {
        'Location':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                },
        'Date':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                },
        'day_of_week':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                }
    },
    'model_regression':
    {
        'Location':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                },
        'Date':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                },
        'day_of_week':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                }
    },
    'model_xgboost':
    {
        'Location':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                },
        'Date':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                },
        'day_of_week':
                {
                'Important_loc':None,
                'Others_loc':None,
                'All_loc':None
                }
    },
}
```

# Load Data


## Load labeled data

```{python}
labeled_df = pd.read_parquet(LABELED_PATH)
print(labeled_df.shape)
labeled_df.head()
```

```{python}
test_df = labeled_df.loc[labeled_df['Date']>=TEST_START_DATE]
test_df = test_df.reset_index(drop = True)
test_df.head()
```

## Load Predicted Data

```{python}
predictions_dict['model_xgboost'] = pd.read_parquet(PREDICTED_XGB_ARIMA_PATH)
predictions_dict['model_xgboost'].head()
```

```{python}
predictions_dict['model_regression'] = pd.read_parquet(PREDICTED_REGRESSION_PATH)
predictions_dict['model_regression'].head()
```

### BaseLine Models

```{python}
def baseline_predict(dataset, shift_val):
    predicted_demand = dataset.groupby(['Location'])['Demand'].shift(shift_val)
    predicted_data = pd.DataFrame(dataset[['Location', 'Date']])
    predicted_data['Predicted_demand'] = predicted_demand
    return predicted_data
```

```{python}
predictions_dict['baseline_last_week'] = baseline_predict(test_df, 7)
```

### Join Predictions and Actual

```{python}
def join_actual_predict(actual_df, predicted_df):
    actual_predicted_df = actual_df.copy()
    actual_predicted_df['Predicted_demand'] = predicted_df['Predicted_demand']
    actual_predicted_df = actual_predicted_df.dropna()
    actual_predicted_df['day_of_week'] = actual_predicted_df['Date'].dt.dayofweek
    return actual_predicted_df
```

```{python}
predictions_dict['baseline_last_week'] = join_actual_predict(test_df,predictions_dict['baseline_last_week'])
predictions_dict['baseline_last_week'].head()
```

```{python}
predictions_dict['model_regression'] = join_actual_predict(test_df,predictions_dict['model_regression'])
predictions_dict['model_regression'].head()
```

```{python}
predictions_dict['model_xgboost'] = join_actual_predict(test_df,predictions_dict['model_xgboost'])
predictions_dict['model_xgboost'].head()
```

### Sort Locations by Demand

```{python}
def sort_locations_on_demand(predictions_dict,sorted_locations_dict):
    for label,predictions_df in predictions_dict.items():
        if (predictions_df is not None):
            sorted_index = predictions_df.groupby('Location')['Demand'].aggregate(['sum']).sort_values('sum', ascending=False)
            sorted_index = sorted_index.reset_index()
            sorted_locations_dict[label] = sorted_index
```

```{python}
sort_locations_on_demand(predictions_dict, sorted_locations_dict)
sorted_locations_dict['model_xgboost'].head()
```

# Mean error Calculation


### Error Columns

```{python}
def calculate_error(actual_predicted_dict: dict):
    for label,actual_predicted_df in actual_predicted_dict.items():
        if (actual_predicted_df is not None):
            actual_predicted_df['error'] = np.abs(
                actual_predicted_df['Demand']-actual_predicted_df['Predicted_demand']
                )
            actual_predicted_df['squared_error'] = np.square(
                actual_predicted_df['Demand']-actual_predicted_df['Predicted_demand']
                )
            actual_Demand_df = np.where(actual_predicted_df['Demand']==0, 1, actual_predicted_df['Demand'])
            actual_predicted_df['percentage_error'] = (
                actual_predicted_df['error']/actual_Demand_df
                )*100
            
```

```{python}
calculate_error(predictions_dict)
predictions_dict['model_regression'].head()
```

### Aggregate Error Columns

```{python}
def calculate_maen_error(actual_predicted_dict: dict, predictions_mean_dict: dict):
    per_columns=['Location', 'Date', 'day_of_week']
    for model,actual_predicted_df in actual_predicted_dict.items():
        if (actual_predicted_df is not None):
            sorted_index = sorted_locations_dict[model]['Location']
            important_actual_predicted_df = actual_predicted_df.loc[actual_predicted_df['Location'].isin(sorted_index[:IMPORTANT_LOCATIONS])]
            other_actual_predicted_df = actual_predicted_df.loc[~actual_predicted_df['Location'].isin(sorted_index[:IMPORTANT_LOCATIONS])]
            for per in per_columns:
                important_error_df = important_actual_predicted_df[[per,'Demand','error', 'percentage_error',]] 
                others_error_df = other_actual_predicted_df[[per,'Demand','error','percentage_error']] 
                all_error_df = actual_predicted_df[[per,'Demand','error','percentage_error']]
                
                important_mean_df = important_error_df\
                                                .groupby(per)\
                                                .agg(mape=('percentage_error','mean'),
                                                    mae=('error','mean'),
                                                    demand_mean=('Demand','mean')) 
                others_mean_df = others_error_df\
                                                .groupby(per)\
                                                .agg(mape=('percentage_error','mean'),
                                                    mae=('error','mean'),
                                                    demand_mean=('Demand','mean')) 
                all_mean_df = all_error_df\
                                            .groupby(per)\
                                            .agg(mape=('percentage_error','mean'),
                                                mae=('error','mean'),
                                                demand_mean=('Demand','mean')) 
                important_mean_df['mape'] = np.where(important_mean_df['mape']>100, 100, important_mean_df['mape'])
                others_mean_df['mape'] = np.where(others_mean_df['mape']>100, 100, others_mean_df['mape'])
                all_mean_df['mape'] = np.where(all_mean_df['mape']>100, 100, all_mean_df['mape'])
                if per == 'Location':
                    important_mean_df = important_mean_df.reindex(sorted_index[:IMPORTANT_LOCATIONS])

                    others_mean_df = others_mean_df.reindex(sorted_index[IMPORTANT_LOCATIONS:])

                    all_mean_df = all_mean_df.reindex(sorted_index)
                
                predictions_mean_dict[model][per]['Important_loc'] = important_mean_df.reset_index()
                predictions_mean_dict[model][per]['Others_loc'] = others_mean_df.reset_index()
                predictions_mean_dict[model][per]['All_loc'] = all_mean_df.reset_index()
                
    
```

```{python}
calculate_maen_error(predictions_dict, predictions_mean_error_dict)
```

```{python}
predictions_mean_error_dict['baseline_last_week']['Date']['Important_loc'].head()
```

### Plot Mape for Models Predicted Demands

```{python}
def plot_mape(predictions_mean_dict, per):
    
    fig, axes = plt.subplots(nrows=(4 if (per == 'Location') else 3 ), ncols=1, figsize=((15,25)if (per == 'Location') else (15,20))) 
    
    for model,mean_df in predictions_mean_dict.items():
        important_df = mean_df[per]['Important_loc']
        others_df = mean_df[per]['Others_loc']
        all_df = mean_df[per]['All_loc']
        if (important_df is not None) and (others_df is not None):
            important_df[per] = important_df[per].astype(str)
            others_df[per] = others_df[per].astype(str)
            all_df[per] = all_df[per].astype(str)

            important_df.plot(x=per,y='mape',kind='line',marker='.',ax = axes[0], label=model)
            if per == 'Location':
                split_size = len(others_df)//2
                others_df[:split_size].plot(x=per,y='mape',kind='line',marker='.',ax = axes[1],label=model)
                others_df[split_size:].plot(x=per,y='mape',kind='line',marker='.',ax = axes[2],label=model)
                all_df.plot(x=per,y='mape',kind='line',ax = axes[3],label=model)
            else:
                others_df.plot(x=per,y='mape',kind='line',marker='.',ax = axes[1],label=model)
                all_df.plot(x=per,y='mape',kind='line',ax = axes[2],label=model)

    axes[0].set_title('Models MAPE for '+str(IMPORTANT_LOCATIONS)+' imortant locations', bbox=dict( alpha=0.5)) 
    axes[1].set_title('Models MAPE for other locations', bbox=dict(alpha=0.5)) 
    axes[-1].set_title('Models MAPE for all locations', bbox=dict(alpha=0.5))

    plot_name = SAVE_PLOT_PATH + 'MAPE_plot per '+per+'.svg'
    plt.savefig(plot_name, format='svg', dpi=1200)  

```

```{python}
plot_mape(predictions_mean_error_dict, 'Location')
```

```{python}
plot_mape(predictions_mean_error_dict, 'Date')
```

```{python}
plot_mape(predictions_mean_error_dict, 'day_of_week')
```

### Plot MAE

```{python}
def plot_mae(predictions_mean_dict, per):
    
    fig, axes = plt.subplots(nrows=(4 if (per == 'Location') else 3 ), ncols=1, figsize=((15,25)if (per == 'Location') else (15,20))) 

    
    for model,mean_df in predictions_mean_dict.items():
        important_df = mean_df[per]['Important_loc']
        other_df = mean_df[per]['Others_loc']
        all_df = mean_df[per]['All_loc']
        if (important_df is not None) and (other_df is not None) and (all_df is not None):

            important_df[per] = important_df[per].astype(str)
            other_df[per] = other_df[per].astype(str)
            all_df[per] = all_df[per].astype(str)
            
            important_df.plot(  x=per,y='mae',kind='line',ax = axes[0],label=model)
            if per == 'Location':
                split_size = len(other_df)//2
                other_df[:split_size].plot(x=per,y='mae',kind='line',ax = axes[1], label=model)
                other_df[split_size:].plot(x=per,y='mae',kind='line',ax = axes[2],label=model)
                all_df.plot(x=per,y='mae',kind='line',ax = axes[3],label=model)
            else:
                other_df.plot(x=per,y='mae',kind='line',ax = axes[1],label=model)
                all_df.plot(x=per,y='mae',kind='line',ax = axes[2],label=model)

    axes[0].set_title('Models MAE for '+str(IMPORTANT_LOCATIONS)+' imortant locations', bbox=dict( alpha=0.5)) 
    axes[1].set_title('Models MAE for other locations', bbox=dict(alpha=0.5)) 
    axes[-1].set_title('Models MAE for all locations', bbox=dict(alpha=0.5)) 

    plot_name = SAVE_PLOT_PATH + 'MAE_plot per '+per+'.svg'
    plt.savefig(plot_name, format='svg', dpi=1200)

```

```{python}
plot_mae(predictions_mean_error_dict, 'Location')
```

```{python}
plot_mae(predictions_mean_error_dict, 'Date')
```

```{python}
plot_mae(predictions_mean_error_dict, 'day_of_week')
```

# Table of Results

```{python}
def create_table_errors(predictions_dict, report_dict):
    for model, error_df in predictions_dict.items():
        if error_df is not None:
            report_dict['MAE']['all_locations'][model] = error_df['error'].mean()
            report_dict['MSE']['all_locations'][model] = error_df['squared_error'].mean()
            report_dict['RMSE']['all_locations'][model] = np.sqrt(error_df['squared_error'].mean())
            report_dict['MAPE']['all_locations'][model] = error_df['percentage_error'].mean()

            error_important_df = error_df.loc[error_df['Location'].isin(sorted_locations_dict[model][:IMPORTANT_LOCATIONS]['Location'])]
            error_others_df = error_df.loc[~error_df['Location'].isin(sorted_locations_dict[model][:IMPORTANT_LOCATIONS]['Location'])]

            report_dict['MAE']['important_lacations'][model] = error_important_df['error'].mean()
            report_dict['MSE']['important_lacations'][model] = error_important_df['squared_error'].mean()
            report_dict['RMSE']['important_lacations'][model] = np.sqrt(error_important_df['squared_error'].mean())
            report_dict['MAPE']['important_lacations'][model] = error_important_df['percentage_error'].mean()
            
            report_dict['MAE']['others_locations'][model] = error_others_df['error'].mean()
            report_dict['MSE']['others_locations'][model] = error_others_df['squared_error'].mean()
            report_dict['RMSE']['others_locations'][model] = np.sqrt(error_others_df['squared_error'].mean())
            report_dict['MAPE']['others_locations'][model] = error_others_df['percentage_error'].mean()
    return report_dict
```

```{python}
report_dict = create_table_errors(predictions_dict, report_dict)
report_df = pd.DataFrame.from_dict({(i,j): report_dict[i][j] 
                            for i in report_dict.keys() 
                            for j in report_dict[i].keys()},
                            orient='index')

report_df.index = pd.MultiIndex.from_tuples(report_df.index)
report_df = report_df.T
report_df = report_df.rename(columns={"('MAPE', 'important_lacations')": "Mape\nhigh_demand_locations"})

```

```{python}
report_df
```

```{python}

```
